{"pages":[],"posts":[{"title":"DL Machine系列-01 安裝Docker-19.03+Nvidia-docker","text":"docker安裝sudo apt-get remove docker docker-engine docker.io用來確保你的環境中沒有docker免得版本衝突，可以點這個網站下載和你作業系統相符的docker安裝檔案。我這邊下載的是19.03.5版本。 接著解壓縮跟copy到bin目錄： 12tar xzvf docker-19.03.5.tgzsudo cp -rf docker/* /usr/local/bin/ 可以透過執行： 12docker --versionsudo docker run hello-world 來確定版本跟能否順利執行。 Nvidia Docker 確認docker版本在19.03以上 linux kernel版本大於3.10(可以透過uname -r確認) 你主機板上裝的GPU架構要在Fermi(2.1)以上(可以上Wiki查看) 還有GPU的Driver要361.93以上(可以用nvidia-smi在終端機查看) 將nvidia的資料庫加到電腦中： 123456curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | \\ sudo apt-key add -distribution=$(. /etc/os-release;echo $ID$VERSION_ID)curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \\ sudo tee /etc/apt/sources.list.d/nvidia-docker.listsudo apt-get update 安裝nvidia-container-toolkit： 1sudo apt-get install -y nvidia-container-toolkit 參考資料：nvidia-docker的wiki bug1-docker路徑問題因為前面安裝docker是用手動安裝的，所以docker的位置跟用sudo apt-get install docker的位置不一樣，所以有以下錯誤碼： 1Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? 接著我嘗試重新啟動docker： 123sudo systemctl restart docker# 以下為outputJob for docker.service failed because the control process exited with error code. See &quot;systemctl status docker.service&quot; and &quot;journalctl -xe&quot; for details 要你執行systemctl status docker.service和journalctl -xe找詳細資料: 123456789101112sudo systemctl status docker.service# 以下為outputdocker.service - LSB: Create lightweight, portable, self-sufficient containers. Loaded: loaded (/etc/init.d/docker; generated) Active: failed (Result: exit-code) since Mon 2019-12-16 23:47:44 CST; 20min ago Docs: man:systemd-sysv-generator(8)12月 16 23:47:44 mars systemd[1]: Starting LSB: Create lightweight, portable, self-sufficient containers....12月 16 23:47:44 mars docker[7032]: * /usr/bin/dockerd not present or not executable12月 16 23:47:44 mars systemd[1]: docker.service: Control process exited, code=exited status=112月 16 23:47:44 mars systemd[1]: docker.service: Failed with result 'exit-code'.12月 16 23:47:44 mars systemd[1]: Failed to start LSB: Create lightweight, portable, self-sufficient containers.. 看到/usr/bin/dockerd，因為安裝的時候dockerd是放在/usr/local/bin/裡面，因此要更改docker.service中的設定，前往/etc/init.d/，編輯docker: 12cd /etc/init.d/vim docker 將檔案中DOCKERD的位置改成上面手動安裝的位置： 12-DOCKERD=/usr/bin/dockerd+DOCKERD=/usr/local/bin/dockerd 接著重啟daemon和docker.service，然後查看docker.service： 12345678910111213141516systemctl daemon-reload &amp;&amp; systemctl restart docker.servicesudo systemctl status docker.service# 以下為outputdocker.service - LSB: Create lightweight, portable, self-sufficient containers. Loaded: loaded (/etc/init.d/docker; generated) Active: active (running) since Tue 2019-12-17 00:08:53 CST; 2s ago Docs: man:systemd-sysv-generator(8) Process: 7724 ExecStart=/etc/init.d/docker start (code=exited, status=0/SUCCESS) Tasks: 23 (limit: 19660) CGroup: /system.slice/docker.service └─7736 /usr/local/bin/dockerd -p /var/run/docker.pid12月 17 00:08:53 mars systemd[1]: Starting LSB: Create lightweight, portable, self-sufficient containers....12月 17 00:08:53 mars docker[7724]: * Starting Docker: docker12月 17 00:08:53 mars docker[7724]: ...done.12月 17 00:08:53 mars systemd[1]: Started LSB: Create lightweight, portable, self-sufficient containers.. 可以看到可以成功執行了～～ 接著試試看nvidia-docker： 12345678910111213# Starting a GPU enabled container$ docker run --gpus all nvidia/cuda nvidia-smi# Start a GPU enabled container on two GPUs$ docker run --gpus 2 nvidia/cuda nvidia-smi# Starting a GPU enabled container on specific GPUs$ docker run --gpus device=1,2 nvidia/cuda nvidia-smi$ docker run --gpus device=UUID-ABCDEF,1 nvidia/cuda nvidia-smi# Specifying a capability (graphics, compute, ...) for my container# Note this is rarely if ever used this way$ docker run --gpus all,capabilities=utilities nvidia/cuda nvidia-smi 如果成功會跟你在電腦中執行nvidia-smi的結果一樣。 因為docker-19.03已經支援使用NVIDIA GPUs作為運行中的設備了。 上面指令有加上--gpu的選項，如果你不要加，可以在Dockerfile上加上： 1234# 用來指定使用的gpu，和上面的--gpu相同功能ENV NVIDIA_VISIBLE_DEVICES all# 用來指定計算資源，跟上面寫的一樣，這個功能很少用到ENV NVIDIA_DRIVER_CAPABILITIES compute,utility bug2-container無法stop, kill只能使用sudo systemctl restart docker來重新啟動docker，這是因為原本我安裝的是19.03.1版本，這版本有無法刪除container的問題，在網路上搜索一段時間後，有一些人也有遇到這個問題，不過是在windows版本上。 簡而言之就是因為一些deadlock導致容器的API沒有任何回應，也就是無法stop,kill的問題。 後來在github上看到有人說19.03.5也就是最新版本，解決了deadlocks的問題，果斷更新，更換/usr/local/內所有從docker-19.03.1.tgz解壓縮的檔案，再重開機就沒有這個問題了。","link":"/2019/12/18/DeepLearning-01/"},{"title":"DL Machine系列-00 環境建置","text":"前言有鑒於每次實驗架設環境都花很多時間，也常常遇到版本更新後某些套件不相容的問題，所以才打算使用Docker來架設深度學習的虛擬環境(絕對不是因為覺得用Docker很帥才用的)，說到深度學習就不得不使用GPU，使用GPU就不得不用nvidia-docker來架設環境，剛剛好本人的實驗室目前有一台電腦正空閒下來，也剛剛好多出一張RTX 2070S，想說利用Docker來一勞永逸這個問題，也順便試試看多GPU的環境是什麼樣的感覺。 電腦配置CPU： AMD Ryen Threadripper 1900X 8-coreMotherBoard：ROG Strix X399-E GammingGPU：RTX 2070 super, GTX 1050RAM：Kingston 16Gx8 2933MHzStorage：2TB SSD*2, 1*1TB m.2 SSDPower：750w金牌電源 Ubuntu 18.04安裝在安裝Ubuntu的時候，會顯示出 install ubuntu/ try ubuntu without installationinstall ubuntu 等等的選項，但是選擇後螢幕變黑屏沒反應。 經過查找，應該是因為Ubuntu對於RTX顯示卡沒有對應的Driver，所以導致這個問題。 我這邊使用另一張顯卡安裝，再去更新Nvidia-driver來避免這個問題。 安裝的時候選擇： 在新安裝的Ubuntu上使用LVM 這是因為之後新增硬碟用LVM來管理。 確認GPU狀態執行ubuntu-drivers devices去確認 如果你只有看到這一項：nvidia-driver-390 - distro non-free，那你必須去將NVIDIA repository加入到你的apt庫。 可以用dpkg -l 'nvidia*'去看電腦上安裝的Nvidia Driver 執行sudo ubuntu-drivers autoinstall安裝driver，完成之後執行nvidia-smi就可以看到： 安裝基本工具12345sudo apt-get updatesudo apt-get upgradesudo apt-get install vim #好用的編輯器sudo apt-get install net-tools curl #用來看網路介面卡sudo apt-get install gparted #硬碟管理工具 設定ip(區域網路)打開/etc/netplan/01-network-manager-all.yaml更改成這樣： 123456789# Let NetworkManager manage all devices on this systemnetwork: version: 2 # renderer: NetworkManager eno1: addresses: [192.168.123.111/24] gateway4: 192.168.111.1 nameservers: addresses: [8.8.8.8,8.8.4.4] 參數說明：eno1： 網卡名稱(可以透過ifconfig查看)addresses： 要指定的ipgateway4： 閘道 ip4(gateway6 閘道 ip6)nameservers： dns 以逗號階隔註：/32 指的是 network mask of 255.255.255.255/24 指的是 network mask of 255.255.255.0 依照個人網路調整即可，用sudo netplan apply就可以套用剛剛的設定了。 安裝vnc遠端操控安裝 xfce4 與 xrdp 12sudo apt-get install xfce4sudo apt-get install xrdp 配置登入環境 12echo xfce4-session &gt; ~/.xsessionsudo vim /etc/xrdp/startwm.sh 將stratum.sh更改： 1234567if test -r /etc/profile; then . /etc/profilefitest -x /etc/X11/Xsession &amp;&amp; exec /etc/X11/Xsession-exec /bin/sh /etc/X11/Xsession+startxfce4 啟動 xrdp 服務： 1sudo service xrdp restart 確認服務正常運行： 1netstat -na | grep 3389 這時就可以透過Windows的遠端桌面連線到你的Linux主機了： 補充可以透過： 1sudo lshw -html &gt; ~/hardware.html 來看這台電腦的硬體配備，用瀏覽器打開即可。","link":"/2019/12/17/DeepLearning-00/"},{"title":"DL Machine系列-02 建立LVM管理儲存空間","text":"前言這台硬碟上裝了5顆硬碟(2顆2.5’ SSD、2顆3.5’ HDD、1顆m.2 SSD)，因為我們實驗室處理的資料量都頗大，動不動就500GB-1TB，如果單純地根據硬碟分開儲存的話，可能會浪費很多剩餘空間，而且在跑資料的時候可能會產生其他資料，這又導致不能預先切割硬碟來符合檔案大小(而且很麻煩)，為了方便合理的利用所有硬碟空間，我決定將硬碟整合起來一起管理。 在找合適的硬碟管理方法的時候，有想過組一個RAID 0的磁碟陣列，不過考慮到之後的擴充需求加上實驗室已經有一台NAS來儲存資料，不需要太擔心資料的完整性，所以查到了LVM的方法來管理資料儲存。 LVM介紹LVM是 Logical Volume Manager(邏輯卷管理)的簡寫，LVM會將一個或多個硬碟的分區在邏輯上集合，可以直接把它當作一顆大硬碟來用，當硬碟空間不足的時候，可以從剩餘空間上劃分一些空間給其他空間不夠的分區使用。 簡單地以一張圖來表示： 不過我這邊只是打算單純地以SSD和HDD兩種不同的硬碟來組成LVM，分別管理讀寫速率不一樣的兩種硬碟。 名詞介紹PV：Physical Volume，物理的磁碟分區，也就是硬碟上的分區，分區要變成PV後，LVM才能利用那個分區。 VG：Volume Group，將所有PV加入VG整合起來，可以理解成一個倉庫或是幾個大的硬碟。 LV：Logical Volume，從VG中劃分空間分配給LV，會建立一個裝置代號放在系統中，即最後被掛載道系統的分區。 經過PV、VG規劃後，可以理解成，把分區整合成一個大的硬碟，再利用這顆硬碟來分割分區或是格式化，不過這顆大硬碟可以增加或是減少分區的容量，而且原本的資料不會受到影響。 LVM建立流程 建立硬碟分區，這裏因為只是想要單純的分成SSD和HDD，所以就直接把整顆硬碟當作一顆分區來建立，格式化的時候記得使用lvm2的格式(在fdisk中編號為8e)。 創建VG，將前面所創立的PV加入到VG中，VG命名建議以vg開頭，這樣容易辨識出這是一個VG。 創建LV，直接設定容量到你要創建的空間，再掛載到系統就行了。 簡單的三個步驟就可以完成創建LVM了，下面以圖示來說明： [實作]LVM硬碟整合先用之前裝過的Gparted把要加入的硬碟全部格式化為lvm2 pv，如果是新硬碟記得要先新增分割表。 另外記得選擇完後Gparted還不會幫你格式化，要記得點選上面的綠色勾勾，才會應用你的配置。 接下來建立VG，這裡我們直接把HDD跟SSD兩個VG創建出來： 12sudo vgcreate vgHDD /dev/sda1 /dev/sdb1sudo vgcreate vgSSD /dev/sda1 /dev/sdb1 這樣我們就創立好兩個VG了，如果要添加新的PV可以使用： 1sudo vgextend YourVG /dev/NewPVDisk 對VG來切割LV出來，這邊使用所有空間，然後用lvdisplay來查看資訊： 1234567891011sudo lvcreate -l 100%FREE -n HDD vgHDDsudo lvcreate -l 100%FREE -n SSD vgSSDsudo lvdisplay# output1LV Path /dev/vgHDD/HDDLV Name HDDVG Name vgHDD# output2LV Path /dev/vgSSD/SSDLV Name SSDVG Name vgSSD 格式化HDD這個LV，再掛載到需要的位置，這邊用mkfs用xfs的格式來格式化硬碟，要使用mkfs.xfs要記得先安裝xfsprogs： 123sudo apt-get install xfsprogssudo mkfs.xfs /dev/vgHDD/HDDsudo mkfs.xfs /dev/vgSSD/SSD 接下來掛載到/mnt，這邊放在/mnt裡面統一管理： 123sudo mkdir /mnt/HDD /mnt/SSDsudo mount /dev/vgHDD/HDD /mnt/HDDsudo mount /dev/vgSSD/SSD /mnt/SSD 管理LVM在網路上找到這張圖： 使用方法就是(PV, VG, LV) + 左邊的指令： 1234# 查看所有LVM的PVsudo pvs# 查看更詳細的資訊sudo pvdisplay 另外如果以後新增了更多硬碟，也可以透過lvcreate來組成RAID1, RAID5, RAID6。 補充因為之前硬碟放在其他系統上運作，所以上面有一些預設的磁區，我發現上面有些詞曲沒刪乾淨，所以遇到了下面這個狀況，硬碟是HDD的硬碟： 看了很討厭，所以就進行了更改： 12345678# 卸載之前掛載的PVsudo umount /dev/vgHDD/HDD# 刪除LVsudo lvremove vgHDD/HDD# 轉移資料，將/dev/sda1裡的資料轉移出去sudo pvmove /dev/sda1# 從VG中移除PVsudo vgreduce vgHDD /dev/sda1 這時候你可以透過Gparted或是用lvm的指令來建立新的lvm分區，再來將新的分區添加到vgHDD中： 1sudo vgextend vgHDD /dev/sda1 接下來重複上面的格式化跟掛載步驟就行。","link":"/2019/12/19/DeepLearning-02/"},{"title":"DL Machine系列-03 Docker","text":"前言網路上關於Docker的資訊已經有很多了，這邊就不多作介紹了，只針對幾個常用和在我的實作上有用到的指令和套件去做介紹。 用一張圖來簡單的說明Docker的架構： PortainerPortainer是一個用來管理Docker的工具，他可以透過網頁來查看或管理目前執行的container等等，也可以很快速地進入一個正在執行的container，簡而言之就是一種用來管理Docker的圖形化介面。 安裝可以用docker search portainer來查看目前有哪些可以用的資源： 123456sudo docker search portainer# outputNAME DESCRIPTION STARS OFFICIAL AUTOMATEDportainer/portainer Making Docker management easy. https://porta… 1439portainer/agent An agent used to manage all the resources in… 50portainer/templates App Templates for Portainer http://portainer… 18 下載： 1docker pull portainer/portainer 依據官方的文件啟動container，當然你可以自訂你想要的port (第一個是host port，第二個是container port)： 1234567docker volume create portainer_datadocker run -d -p 9000:9000 \\--name portainer \\--restart always \\-v /var/run/docker.sock:/var/run/docker.sock \\-v portainer_data:/data \\portainer/portainer 打開瀏覽器就能看到： 這樣就可以管理docker的image、container跟volume，還可以看到其他的資源。 常用Docker指令記錄一些常用的Docker指令，以備不時之需，不過我想protainer應該可以取代大部分功能： 12345678910111213141516171819202122# 查看目前的imagedocker images# 刪除imagedocker rmi [OPTIONS] IMAGE [IMAGE...]# 查看目前運行的 containerdocker ps# 查看目前全部的 container（ 包含停止狀態的 container ）docker ps -a# 停止 Containerdocker stop [OPTIONS] CONTAINER [CONTAINER...]# 删除 Containerdocker rm [OPTIONS] CONTAINER [CONTAINER...]# 查看 Container 詳細資料docker inspect [OPTIONS] NAME|ID [NAME|ID...]# 查看 logdocker logs [OPTIONS] CONTAINER# 顯示容器資源 ( CPU , I/O ...... )docker stats [OPTIONS] [CONTAINER...]# 停止指定的 CONTAINER 中全部的 processesdocker pause CONTAINER [CONTAINER...]# 恢復指定暫停的 CONTAINER 中全部的 processesdocker unpause CONTAINER [CONTAINER...] docker stop : process 級別。 docker pause: container 級別。 實作Deep Learning環境我這裡選擇的image是ubuntu18.04，然後透過ARG來新增使用者： 12345FROM ubuntu:18.04MAINTAINER jim jimhsu11@gmail.comARG USERNAMEARG USERPWD DEBIAN_FRONTEND noninteractive接下來這個步驟很重要： 12# debconf to be non-interactiveENV DEBIAN_FRONTEND noninteractive 因為ubuntu在安裝的時候，某些套件會需要輸入指令，這邊將它設定成沒有交互介面的模式來安裝。 Add User接著就是新增使用者，這邊新增使用者主要是為了之後的xrdp套件，在run docker的時候可以不用再去建立使用者，不過在build的時候要記得加上ARG參數: 123456# Update and Add UserRUN apt-get update \\ &amp;&amp; apt-get install -y vim sudo wget \\ &amp;&amp; useradd -ms /bin/bash ${USERNAME}\\ &amp;&amp; sudo adduser ${USERNAME} sudo\\ &amp;&amp; echo ${USERNAME}:${USERPWD} | chpasswd xrdp這邊安裝xrdp套件，讓Windows系統可以透過遠端桌面連線連線到Container： 123456# xrdpRUN apt-get update \\ &amp;&amp; apt-get install -y xfce4 xfce4-goodies xorg dbus-x11 x11-xserver-utils xrdp \\ &amp;&amp; echo xfce4-session &gt; /home/${USERNAME}/.xsession \\ &amp;&amp; sed -i &quot;s/^exec.*Xsession$/startxfce4/g&quot; &quot;/etc/xrdp/startwm.sh&quot; \\ &amp;&amp; service xrdp restart 這邊跟一般安裝xrdp的過程一樣，其中sed是將/etc/xrdp/startwm.sh最後一行替換成startxfce4。 Anaconda這邊使用Anaconda來管理python的套件，雖然已經使用Docker來隔離系統了，不過還是習慣用Anaconda來建立python環境： 123456# Install AnacondaRUN wget --quiet https://repo.continuum.io/archive/Anaconda3-5.0.1-Linux-x86_64.sh -O ~/anaconda.sh \\ &amp;&amp; /bin/bash ~/anaconda.sh -b -p /opt/conda \\ &amp;&amp; rm ~/anaconda.sh \\ &amp;&amp; echo &quot;export PATH=/opt/conda/bin:$PATH&quot; &gt;&gt; /home/${USERNAME}/.bashrc \\ &amp;&amp; sudo chown -R ${USERNAME}:${USERNAME} /opt/conda 這邊wget後面的網址可以自己去更改，找符合自己需求的版本來安裝。 然後安裝Anaconda的時候會需要輸入一些指令，所以用-b使用預設值安裝。 -p後面接的是安裝位置，這邊也可以自己去調整。 cuda &amp; cudnn我這邊cuda使用的版本是10.0，雖然在系統上是安裝的版本是10.1，不過經過測試，是不影響使用的。 我是使用Nvidia/cuda的Dockerfile指令來安裝cuda和cudnn，分別將nvidia/cuda:10.0-base-ubuntu18.04、nvidia/cuda:10.0-runtime-ubuntu18.04和nvidia/cuda:10.0-cudnn7-runtime-ubuntu18.04上需要的Dockerfile指令，加到自己的Dockerfile： 12345678910111213141516171819202122232425262728293031323334353637383940414243#-------------------From Nvidia-------------------# Nvidia install listRUN apt-get update \\ &amp;&amp; apt-get install -y --no-install-recommends gnupg2 curl ca-certificates \\ &amp;&amp; curl -fsSL https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub | apt-key add - \\ &amp;&amp; echo &quot;deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 /&quot; &gt; /etc/apt/sources.list.d/cuda.list \\ &amp;&amp; echo &quot;deb https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 /&quot; &gt; /etc/apt/sources.list.d/nvidia-ml.list \\ &amp;&amp; apt-get purge --autoremove -y curl \\ &amp;&amp; rm -rf /var/lib/apt/lists/*ENV CUDA_VERSION 10.0.130ENV CUDA_PKG_VERSION 10-0=$CUDA_VERSION-1# For libraries in the cuda-compat-* package: https://docs.nvidia.com/cuda/eula/index.html#attachment-aRUN apt-get update \\ &amp;&amp; apt-get install -y --no-install-recommends \\ cuda-cudart-$CUDA_PKG_VERSION \\ cuda-compat-10-0 \\ &amp;&amp; ln -s cuda-10.0 /usr/local/cuda \\ &amp;&amp; rm -rf /var/lib/apt/lists/*ENV PATH /usr/local/nvidia/bin:/usr/local/cuda/bin:${PATH}ENV LD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64ENV NCCL_VERSION 2.4.2RUN apt-get update \\ &amp;&amp; apt-get install -y --no-install-recommends \\ cuda-libraries-$CUDA_PKG_VERSION \\ cuda-nvtx-$CUDA_PKG_VERSION \\ libnccl2=$NCCL_VERSION-1+cuda10.0 \\ &amp;&amp; apt-mark hold libnccl2 \\ &amp;&amp; rm -rf /var/lib/apt/lists/*ENV CUDNN_VERSION 7.6.0.64LABEL com.nvidia.cudnn.version=&quot;${CUDNN_VERSION}&quot;RUN apt-get update \\ &amp;&amp; apt-get install -y --no-install-recommends \\ libcudnn7=$CUDNN_VERSION-1+cuda10.0 \\ &amp;&amp; apt-mark hold libcudnn7 \\ &amp;&amp; rm -rf /var/lib/apt/lists/*#-------------------Nvidia End------------------- 這邊有試過用nvidia本身的image來建立，不過失敗了，後來將nvidia上Dockerfile複製自己需要的部分卻成功了，原因沒有深究，如果有人知道的話，歡迎留言告訴我。 以上就是我的Dockerfile所有的內容。 Build &amp; Run &amp; Upload上面可以看到我的功能是一層一層添加的，實際上實作完一層，我就會build和run一次那個Dockerfile，以確保我的Dockerfile沒有寫錯，所以接下來就是將剛剛寫完的Dockerfile建立起來。 Build Dockerfile進入Dockerfile所在的資料夾，執行以下指令： 123sudo docker build -t image_name:tag \\--build-arg USERNAME=username \\--build-arg USERPWD=yourpassword . -t後面接的是image的名字跟tag，USERNAME跟USERPWD就是登入系統時要輸入的帳密，這樣image就建立好了。 Run Image執行下列命令就可以進入到創立的container了： 123456sudo docker run --gpus device=1 -it \\-p 33890:3389 \\-v /mnt/SSD:/data/SSD \\-v /mnt/HDD:/data/HDD \\-v /docker_config/config:/config \\image_name:tag --gpus:可以指令你要用的gpu，當然是要你電腦上有安裝複數的gpu才能指令，不然可以直接用--gpus all來使用全部的gpu。 -p:因為有使用xrdp套件，而這個套件使用的port是3389，所以要將container的port映射到主機上的port，這邊選擇加上一個0。 -v:可以將主機上的資料夾位置映射到container上面，也可以是docker的volume映射到container上。這邊要注意的是冒號，冒號前是主機上的位置；後面是container上的位置。 -it：建立好後會直接進入container。 接下來要啟動xrdp套件才可以連線進去，執行： 1service xrdp restart 啟動遠端桌面連線程式，輸入你主機的ip： 再輸入前面設定的帳號密碼： 進入到你的環境後，要記得進入Setting Manager： 打開Preferred Applications： 選擇Utilities，將預設的Terminal Emulator改成Xfce Terminal： 這樣就可以用Terminal了。 Docker Hub實作完自己的Dockerfile之後，用Docker Hub備份或是分享到網上。 第一步要當然是註冊一個帳號，再利用docker login來登入： 12345docker login# outputLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.Username: usernamePassword: yourpassword 登入完，直接用docker push來上傳就行了: 1docker push yourusername/image_name:tag 連結Docker Hub：https://hub.docker.com/repository/docker/augustushsu/ubuntu18.04-xrdp Github：https://github.com/AugustusHsu/Docker-DL","link":"/2019/12/23/DeepLearning-03/"},{"title":"GAN系列-00 Generative Adversarial Network 生成對抗網路","text":"GAN介紹Generative Adversarial Network(生成對抗網路，簡稱GAN)，算是這十年來最紅的技術，許多在機器學習領域的大佬都說：「GAN是這10年、20年來最酷、最有趣的想法。」，在網路上GAN的介紹文已經算是很氾濫了，這邊就簡單的介紹一下。 GAN是由Ian Goodfellow所在2014年所提出的方法，原本是作為非監督式學習(Unsupervised learning)使用，不過在這幾年的不斷使用，它也被證明對監督式學習、半監督式學習、強化學習是有幫助的。GAN常被用於： 風格轉換(Style Transfer)，這是一種在GAN裡面最被人所知的應用，泛指可以將一種類型圖像轉換到另一種類別．例如：將照片轉換成梵谷風格的圖畫、將線稿轉換成上好色的圖片、將圖片中的馬變成斑馬等等。 生成高解析度的圖像．透過GAN將原本低解析度的圖片變成高解析度的．這個常用於：將老電影修補、轉換成高解析度的、同理也能將遊戲中原本低解析度的紋理透過GAN生成更清晰的紋理圖像等等。 提供更多資料，透過GAN可以生成和和原始資料相似的圖片或是資料．因為這些生成的資料假以亂真，可以將這些資料作為訓練資料來加強原本訓練的網路。 還有許多應用，如在天文、醫學、時裝…等等，就不一一列舉了。 說了那麼多的應用，那GAN到底是什麼用了什麼概念讓它有這麼強大的能力呢？其實這個概念不難，就像是他本身名字所敘述的：對抗，GAN利用了兩個網路，分別是Generator跟Discriminator，來對抗彼此、精進本身，來達到目的。可以想像成偽造者跟鑑定家之間的比拼，以鈔票來舉例就是製造偽鈔者跟警察兩者的比拼，前者不斷製造假鈔來讓後者辨識，直到假鈔真假難辨為止。 GAN具體的架構如同標題上方的圖片，Generator生成虛假的例子交給Discriminator辨識，Discriminator再將辨識結果回饋給Generator，透過不斷的訓練，讓兩個網路越來越強大，Generator生成的圖片就會越來越像真的了。 各種GAN實作GAN經過這些年的發展有了許多的變體，來適應各種挑戰，這邊列舉了一些常見的GAN模型，將透過Tensorflow 2.x來實作： Generative Adversarial Network Conditional Generative Adversarial Nets Deep Convolutional Generative Adversarial Network WGAN WGAN-GP CycleGAN StarGAN IRGAN SeqGAN","link":"/2020/05/30/GAN-00/"},{"title":"DL Machine系列-04 Docker Hub Automated Build","text":"Docker Hub Automated BuildsAutomated Builds是Docker Hub上提供的功能，它可以在你Github上有更新的時候，自動地幫你Build你的Dockerfile，產生一個新的Image。 連結Github點選頭像可以看到Account Setting：再點選Linked Accounts，跟你的Github做連結：連結完會像這樣： 點選你要連結的Docker Repository，接著點選Build： 再來點選Configure Automated Builds： 可以看到你帳號的右邊可以選擇你要連結的Github Repository： 在Configure Automated Builds下面有一些設定可以調整，可以設定不同branch有不同的tag可以設定，它有舉一些例子、還有命名規則可以去查看。 Docker Hub Build Error在Docker Hub的時候，會看到下面這個狀況： 1...returned a non-zero code: 2 後來經過測試發現，這是因為我有使用ARG這個參數導致的，因為在Build你的Docker Image的時候會需要加上這些參數： 123sudo docker build -t image_name:tag \\--build-arg USERNAME=username \\--build-arg USERPWD=yourpassword . 雖然說在Docker Hub上面有： BUILD ENVIRONMENT VARIABLES 可以調整，不過我當時怎麼調整都會有問題。 所以後來我直接將Dockerfile加上預設值： 1234-ARG USERNAME-ARG USERPWD+ARG USERNAME=username+ARG USERPWD=yourpassword 這樣就可以成功Automated Build你的Dockerfile了。","link":"/2019/12/27/DeepLearning-04/"},{"title":"GAN系列-01 Generative Adversarial Network","text":"Generative Adversarial Network前言GAN基本的概念前一篇有稍微介紹過了，然而要怎麼證明這個概念要如何套用到類神經網路呢?Goodfellow透過了Minimax Theorem來訓練網路，詳細證明過程可以看Scott Rome的Blogger，裡面有很詳細的介紹了怎麼透過Shannon Entropy跟Kullback-Leibler Divergence來一步一步的證明怎麼可以收斂(Nash Equilibrium)。下面是整個GAN的Objective Function： $$ \\LARGE{\\min_{G}\\max_{D}V(D,G)=\\mathbb{E}_{x\\sim p_{data}(x)}[\\log D(x)]+\\mathbb{E}_{z\\sim p_z(z)}[\\log (1-D(G(z)))]} $$ 演算法我把GAN的演算法翻成中文： Adversarial Attack在網路上找資料的時候，看到一篇Goodfellow在OpenAI發的Adversarial Example，上面有一個例子： 這些例子大多是在圖像分類任務中找到的，這代表了當時的深度學習模型可能不穩定，也有可能會被惡意利用導致有安全疑慮。Adversarial Attack主要是將圖片加上特定的bias就可以讓分類器誤判，讓研究者對模型的信心下降、也有可能利用這個漏洞製造出一個特定的輸出，當然也可能反過來，把一個特定的輸入修改到讓輸出是特定值。 同樣的道理，我們可以透過對抗用Generator使分類器獲得的樣本多樣性更高，或者說分佈更廣些，也就是這樣會加強模型，讓模型的泛化性更高，詳細的內容可以看網站上的敘述，除了上面圖片的例子，Goodfellow還用了其他類別的資料來展示，有興趣的可以去研讀一下那篇文章。 前處理和類神經網路資料集 &amp; 網路架構這邊使用MNIST當作訓練資料，不過因為是要訓練GAN所以要訂出一個noise，而這邊的noise主要是為了Generator在產生圖片的時候用的，因為在每個Epoch都使用固定的noise當作網路的輸入，就可以觀察到對於同樣noise的輸出圖片在訓練過程中的變化了： 12345678910111213141516import tensorflow as tffrom tensorflow.keras.datasets.mnist import load_datafrom args import parseropts = parser()[(train_x, train_y), (test_x, test_y)] = load_data('mnist.npz')train_images = train_x.reshape(train_x.shape[0], 28, 28, 1).astype('float32')train_images = (train_images - 127.5) / 127.5train_dataset = tf.data.Dataset.from_tensor_slices(train_images)train_dataset = train_dataset.shuffle(opts.BUFFER_SIZE)train_dataset = train_dataset.batch(opts.BATCH_SIZE)noise = tf.random.normal([opts.num_examples_to_generate, opts.noise_dim]) 對於網路的架構，我簡單的使用全連結層來架構Generator跟Discriminator，而非擅長處理圖像資料的CNN： 12345678910111213141516171819202122232425262728293031import tensorflow as tffrom tensorflow.keras import Model, layersclass Dis_Net(Model): def __init__(self): super(Dis_Net, self).__init__(self) self.Dense = tf.keras.Sequential([ layers.Flatten(), layers.Dense(512, activation='relu'), layers.Dense(256, activation='relu'), layers.Dense(128, activation='relu'), layers.Dense(1)]) def call(self, vec): output = self.Dense(vec) return output class Gen_Net(Model): def __init__(self, channels=1): super(Gen_Net, self).__init__(self) self.channels = channels self.Dense = tf.keras.Sequential([ layers.Dense(128, activation='relu'), layers.Dense(256, activation='relu'), layers.Dense(512, activation='relu'), layers.Dense(28 * 28 * self.channels, activation='tanh'), layers.Reshape((28, 28, self.channels))]) def call(self, vec): output = self.Dense(vec) return output Gen &amp; Dis Net and Optimizer將Generator跟Discriminator還有Optimizer定義出來，跟一般訓練網路不太一樣，Optimizer有兩個，分別對應Generator跟Discriminatotr，然後Optimizer我使用的是Adam： 12345Generator = Gen_Net()Discriminator = Dis_Net()G_opt = tf.keras.optimizers.Adam(opts.lr, opts.beta_1)D_opt = tf.keras.optimizers.Adam(opts.lr, opts.beta_1) Loss的部分對於Disciminator跟Generator用的是Binary的Cross Entropy： 12345678910111213141516import osimport tensorflow as tffrom args import parseropts = parser()cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)def generator_loss(fake_output): return cross_entropy(tf.ones_like(fake_output), fake_output)def discriminator_loss(real_output, fake_output): real_loss = cross_entropy(tf.ones_like(real_output), real_output) fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output) # total_loss = real_loss + fake_loss return real_loss, fake_loss 訓練過程訓練過程跟其他的差不多，計算loss、更新網路的過程、記錄需要紀錄的各個參數等等。 Each Epoch Training對於網路的訓練跟一般比較不一樣，主要是因為這邊有兩個網路需要更新，所以會有兩個GradientTape分別來更新兩個網路。其中loss是一個list，裡面每一個item是一個tf.keras.metrics.Mean()，用來記錄各個loss： 1234567891011121314151617181920212223@tf.functiondef train_step(images, loss): noise = tf.random.normal([opts.BATCH_SIZE, opts.noise_dim]) with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: generated_images = Generator(noise, training=True) real_output = Discriminator(images, training=True) fake_output = Discriminator(generated_images, training=True) gen_loss = generator_loss(fake_output) real_loss, fake_loss = discriminator_loss(real_output, fake_output) disc_loss = real_loss + fake_loss loss[0].update_state(real_output) loss[1].update_state(fake_output) loss[2].update_state(gen_loss) loss[3].update_state(disc_loss) gradients_of_gen = gen_tape.gradient(gen_loss, Generator.trainable_variables) gradients_of_dis = disc_tape.gradient(disc_loss, Discriminator.trainable_variables) G_opt.apply_gradients(zip(gradients_of_gen, Generator.trainable_variables)) D_opt.apply_gradients(zip(gradients_of_dis, Discriminator.trainable_variables)) Whole Training Process將前面所寫的兜在一塊就是整體的訓練過程： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546def train(train_dataset): # Initial Log File log_path = os.path.join(opts.LOG_PATH) if not os.path.exists(log_path): os.mkdir(log_path) csv_path = os.path.join(log_path, 'loss.csv') with open(csv_path, 'w') as f: f.write('epoch,Real_P,Fake_P,Gen_loss,Dis_loss\\n') format_str = '{:5d},{:.6f},{:.6f},{:.6f},{:.6f}\\n' dis_r_p = tf.keras.metrics.Mean() dis_f_p = tf.keras.metrics.Mean() G_loss = tf.keras.metrics.Mean() D_loss = tf.keras.metrics.Mean() loss = [dis_r_p, dis_f_p, G_loss, D_loss] # Training for epoch in range(opts.epochs): start = time.time() for image_batch in tqdm(train_dataset.as_numpy_iterator()): train_step(image_batch, loss) # Record Loss with open(csv_path, 'a') as f: f.write(format_str.format(epoch, loss[0].result().numpy(), loss[1].result().numpy(), loss[2].result().numpy(), loss[3].result().numpy())) loss[0].reset_states() loss[1].reset_states() loss[2].reset_states() loss[3].reset_states() # Each Epoch Save Image generate_and_save_images(Generator, epoch + 1, noise) # Save the model every 15 epochs if (epoch + 1) % 15 == 0: Gen_save_path = os.path.join(opts.MODEL_PATH, 'Generator') Dis_save_path = os.path.join(opts.MODEL_PATH, 'Discriminator') Generator.save_weights(Gen_save_path) Discriminator.save_weights(Dis_save_path) print ('Time for epoch {} is {:.3f} sec'.format(epoch + 1, time.time()-start)) time.sleep(0.2) Result在這個Demo中，每個Epoch都用前面設定的固定noise生成16張圖片，以下訓練過程中的變化： 結論一直知道GAN是一個很強也很好用的技術，但是一直沒機會接觸到，直到最近終於有機會來學習這個技術，這個是目前火紅的GAN的原型，其他的GAN我再找時間一一實現，畢竟這是一個系列文(雖然更的很慢XD)。 Github：GAN-01 Generative Adversarial Network","link":"/2020/06/25/GAN-01/"},{"title":"Neural Network-02 Triplet Loss Example at MNIST","text":"前言Triplet Loss在FaceNet那篇論文中，主要是要讓屬於相同一個人的人臉圖片在一個Latent Space中越靠近越好，而讓不屬於這個人的人臉在這個Latent Space中遠離這個人，在這裡我使用MNIST資料集來取代人臉資料，將具有相同類別的手寫圖片彼此聚在一起，讓不同的數字之間有一定的差距。 以下的內容為個人理解，如有其他見解歡迎留言討論～ 前處理和類神經網路首先先定義出MNIST資料要如何使用，再來設計類神經網路，最後將網路和Optimizer使用到實際的訓練過程上。 資料集 &amp; 網路架構這邊使用Tensorflow的程式碼直接將MNIST的資料load進來，再將資料normalize到-1到1之間： 12345678910111213141516import tensorflow as tffrom tensorflow.keras.datasets.mnist import load_datafrom args import parseropts = parser()[(train_x, train_y), (test_x, test_y)] = load_data('mnist.npz')test_x = test_x.reshape(test_x.shape[0], 28, 28, 1).astype('float32')test_x = (test_x - 127.5) / 127.5train_images = train_x.reshape(train_x.shape[0], 28, 28, 1).astype('float32')train_images = (train_images - 127.5) / 127.5train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_y))train_dataset = train_dataset.shuffle(opts.BUFFER_SIZE)train_dataset = train_dataset.batch(opts.BATCH_SIZE).take(20) 這邊簡單的用兩層CNN加上一層全連結層，並且在最後做一個l2 normalize，將embedding的範圍限制住，通常在做Triplet的時候，都會做l2 normalize讓經過Triplet Net之後的Vector限制在一個範圍內： 12345678910111213141516171819202122import tensorflow as tffrom tensorflow.keras import Model, layersclass Triplet_Net(Model): def __init__(self): super(Triplet_Net, self).__init__(self) self.emb_layer = tf.keras.models.Sequential([ layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'), layers.LeakyReLU(), layers.Dropout(0.3), layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'), layers.LeakyReLU(), layers.Dropout(0.3), layers.Flatten(), tf.keras.layers.Dense(200)]) self.l2_norm = layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) def call(self, img, training=True): vec = self.emb_layer(img) vec = self.l2_norm(vec) return vec Triplet Net and Optimizer將Triplet Net和Optimizer定義出來： 1234567method = 'semi_hard'# method = 'batch_hard'triplet_net = Triplet_Net()TripletLoss = tfa.losses.TripletSemiHardLoss(margin=opts.margin)# TripletLoss = tfa.losses.TripletHardLoss(margin=opts.margin)optimizer = tf.keras.optimizers.Adam(opts.lr, opts.beta) 訓練過程接下來就是將每個Epoch中如何計算loss和如何更新網路的過程定義出來，將訓練過程中各個參數記錄下來。 Each Epoch Training定義每個Epoch訓練過程的function，在前面加上@tf.function可以讓原本Tensorflow的Eager mode編譯成Gragh的形式，通常這意味著可以執行的更快，這也是為什麼這邊紀錄loss跟norm需要用到tf.keras.metrics.Mean()來記錄，因為這邊只使用Tensorflow的物件的話，可以讓整體的速度提升： 1234567891011121314norm = tf.keras.metrics.Mean()loss = tf.keras.metrics.Mean()@tf.functiondef train_step(images, label): with tf.GradientTape() as tape: trip_emb = triplet_net(images, training=True) triplet_loss = TripletLoss(label, trip_emb) loss.update_state(triplet_loss) triplet_loss = tape.gradient(triplet_loss, triplet_net.trainable_variables) optimizer.apply_gradients(zip(triplet_loss, triplet_net.trainable_variables)) norm.update_state(tf.norm(triplet_net.emb_layer(images, training=False), axis=1)) Whole Training Process整體的訓練過程如下： 12345678910111213def train(train_dataset): # Training for epoch in range(opts.epochs): start = time.time() for image_batch, label_batch in train_dataset.as_numpy_iterator(): train_step(image_batch, label_batch) print(format_str.format(epoch+1, norm.result().numpy(), loss.result().numpy())) norm.reset_states() loss.reset_states() Result這邊會展示在訓練過程中紀錄的參數和經過Triplet loss訓練後整體Embedding的變化，分為Batch Hard跟Semi-Hard。 Batch Hard只選擇最短的AN距離和最長的AP距離，詳細可以參考前一篇。 PCA-2d使用PCA將各個Epoch中，從Triplet Net出來的200維度的資料降到2維的平面空間上： PCA-3d這邊則是在3維立體空間的示意圖： Triplet Loss每個Epoch中記錄的Loss的變化： Loss會降低到margin，之後就不會再下降了，這是因為選擇的triplet例子都是最難的，而最難的則至少會包含margin，除非在整個Embedding中每筆資料都符合Triplet的定義(機率極低)，而此時loss會是0。 Norm算Embedding Vector的各項平方和再開根號，這邊取的值是在經過l2_norm之前的Vector： 整個norm會逐步上升，這是因為經過Triplet Net的Vector各維度會逐步變大，好符合Tripelt Loss。 Semi-Hard選擇AP到AP+margin之間的AN距離，來計算loss，詳細可以參考前一篇。 PCA-2d使用PCA將各個Epoch中，從Triplet Net出來的200維度的資料降到2維的平面空間上： PCA-3d這邊則是在3維立體空間的示意圖： Triplet Loss每個Epoch中記錄的Loss的變化： Norm算Embedding Vector的各項平方和再開根號，這邊取的值是在經過l2_norm之前的Vector： 可以看到norm在降低之後逐步變高，這是因為一開始選擇的例子可以透過些微的調整而讓各個資料符合tirplet的定義，而後調道不能再調的時候，只好發散整個Embedding讓norm越來越大，這也是為什麼需要在Triplet Net後面加上l2 norm的原因。 結論透過PCA降維到2維或是3維，可以看到Semi-Hard的效果好得多，個人猜測因為Batch Hard只選擇最難的例子導致在訓練過程中所看見的資料太少，也可以說最難的資料無法代表那個Batch中的資料。 Github：NeuralNetwork-02 Triplet Loss Example at MNIST","link":"/2020/06/10/NeuralNetwork-02/"},{"title":"Neural Network-01 Batch Hard and Semi-Hard Triplet Loss","text":"Triplet LossTriplet Loss的介紹，相信在網路上已經有許多例子了，用途跟作用這邊就不多作介紹，將triplet的公式列出來，直接進入正題： $$\\LARGE{\\mathcal{L_{triplet}}=\\max{(\\sum_{i=1}^N[||f^a_i - f^p_i||_2^2-||f^a_i - f^n_i||_2^2 + margin] ,\\ 0)}}$$這邊會依序測試兩種不一樣的Triplet來計算Triplet Loss，分別是： Batch Hard Semihard Sample Data首先要先Sample出兩個不同的Embedding資料，直接使用numpy的random來產生兩個隨機的Embedding。這邊設定Batch Size是64、每筆資料的維度為1024、Margin設定為0.3、另外Label這邊設定是每筆都是獨立的資料，所以每一筆資料對應一個label： 1234567891011import numpy as npbatch = 64emb_dim = 1024np.random.seed(1234)emb1 = np.random.rand(batch,emb_dim).astype(np.float32)np.random.seed(2345)emb2 = np.random.rand(batch,emb_dim).astype(np.float32)margin = 0.3labels = np.arange(batch) Triplet Loss (Batch Hard)直接將最小的AN距離減掉最大的AP距離加上margin，此為Batch Hard的Triplet Loss。 Distance Metric在Tensorflow Addons原始碼中使用square再加起來等價於$XX^T$取對角的element，不過不確定跟目前使用的方法計算複雜度的差距： 12345# 矩陣相乘再取對角的elementxx = np.matmul(x, np.transpose(x))xx = np.diag(xx)# 使用square再根據axix=1相加xx = tf.math.reduce_sum(tf.math.square(x), axis=[1], keepdims=True) 針對一個batch所有的資料兩兩計算，形成一個Batch*Batch的metric： 這裡計算每一筆的距離，回傳的是一個shape=(batch, batch)的metric： 1234567891011121314151617181920212223242526272829303132333435def np_distance_metric(embedding, squared=True): &quot;&quot;&quot; Args: embedding: float32, with shape [n, d], (batch_size, d) Returns: dist: float32, with shape [m, n], (batch_size, batch_size) &quot;&quot;&quot; # |x-y|^2 = x^2 - 2xy + y^2 xy = np.matmul(embedding, np.transpose(embedding)) square_norm = np.diag(xy) xx = np.expand_dims(square_norm, 0) yy = np.expand_dims(square_norm, 1) distances = np.add(xx, yy) - 2.0 * xy ''' (batch_size,1)-(batch_size,batch_size): Equivalent to each column operation (batch_size,batch_size)+(1,batch_size): Equivalent to each row operation ''' # Deal with numerical inaccuracies. Set small negatives to zero. distances = np.maximum(distances, 0.0) # Get the mask where the zero distances are at. error_mask = np.less_equal(distances, 0.0).astype(np.float32) if not squared: # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal) # we need to add a small epsilon where distances == 0.0 distances = np.sqrt(distances + error_mask * 1e-16) # Undo conditionally adding 1e-16. distances = np.multiply(distances, np.logical_not(error_mask),) num_data = np.shape(embedding)[0] # Explicitly set diagonals to zero. mask_offdiagonals = np.ones_like(distances) - np.diag(np.ones([num_data])) distances = np.multiply(distances, mask_offdiagonals) return distances Mask_masked_minimum做的簡而言之就是將乘上mask後的data中根據dim取其最小值，具體步驟是： 首先將每筆資料對應的最大值選取出來，命名為：axis_maximums，將Distance Metric減掉這個最大值(axis_maximums)，再乘上mask選取出需要比較的數值，接下來根據dim取出對應行或列中最小值，最後再將axis_maximum加回去就可以得到需要的結果，然後需要注意這邊有keepdims，所以會是(batch, 1)的形式。 具體的實現過程為： 123456789101112def np_masked_minimum(data, mask, dim=1): &quot;&quot;&quot;Computes the axis wise minimum over chosen elements. Args: data: float32, with shape [n, m], (batch_size, batch_size) mask: boolean, with shape [n, m], (batch_size, batch_size) dim: int, the dimension which want to compute the minimum. Returns: masked_minimums: float32, with shape [n, 1], (batch_size, batch_size) &quot;&quot;&quot; axis_maximums = np.max(data, dim, keepdims=True) masked_minimums = (np.min(np.multiply(data - axis_maximums, mask), dim, keepdims=True) + axis_maximums) return masked_minimums _masked_maximum做的事情和上面一樣，不過得到的為最大值： 123456789101112def np_masked_maximum(data, mask, dim=1): &quot;&quot;&quot;Computes the axis wise maximum over chosen elements. Args: data: float32, with shape [n, m], (batch_size, batch_size) mask: boolean, with shape [n, m], (batch_size, batch_size) dim: int, the dimension over which to compute the maximum. Returns: masked_maximums: N-D `Tensor`. &quot;&quot;&quot; axis_minimums = tf.math.reduce_min(data, dim, keepdims=True) masked_maximums = (tf.math.reduce_max(tf.math.multiply(data - axis_minimums, mask), dim, keepdims=True) + axis_minimums) return masked_maximums 定義出以上function之後，就可以開始進行整個Triplet Loss的計算。 Batch Hard首先先算出pairwise的距離矩陣pdist_matrix，再利用labels計算出row index和column index對應的embedding是否有相同的label(adjacency)，相反可以得出不同的label(adjacency_not)。 如此就可以得到negative所在的mask和positive所在的mask，利用前面的mask function找出hardest的negative，同理利用前面的adjacency再去掉相同index的element就可以得到positive的mask，也就是得到hardest的positive。 有了hardest的positive跟negative就可以直接帶入triplet的公式： 123456789101112131415161718192021222324252627282930313233343536373839def np_triplet_batch_hard(labels, embedding, margin, soft): ''' batch all triplet loss of a batch ------------------------------------ Args: labels: Label Data, shape = (batch_size,1) embedding: embedding vector, shape = (batch_size, vector_size) margin: margin, scalar soft:: use log1p or not, boolean Returns: triplet_loss: scalar, for one batch ''' # Reshape label tensor to [batch_size, 1]. lshape = np.shape(labels) labels = np.reshape(labels, [lshape[0], 1]) # Build pairwise squared distance matrix. pdist_matrix = _distance_metric(embedding, squared=True) # Build pairwise binary adjacency matrix. adjacency = np.equal(labels, tf.transpose(labels)).astype(np.float32) # Invert so we can select negatives only. adjacency_not = np.logical_not(adjacency).astype(np.float32) # hard negatives: smallest D_an. hard_negatives = _masked_minimum(pdist_matrix, adjacency_not) batch_size = np.size(labels) mask_positives = adjacency - np.diag(np.ones([batch_size])) # hard positives: largest D_ap. hard_positives = _masked_maximum(pdist_matrix, mask_positives) if soft: triplet_loss = np.log1p(np.exp(hard_positives - hard_negatives)) else: triplet_loss = np.maximum(hard_positives - hard_negatives + margin, 0.0) # Get final mean triplet loss triplet_loss = np.mean(triplet_loss) return triplet_loss Triplet Loss (Semi-Hard)前面定義出了Batch Hard的Triplet Loss是怎麼運作的，接下來要介紹什麼是Semi-Hard的Tirplet，簡而言之就是要找那些AN&gt;AP但&lt;margin的pair。 這裡分成5個部分來分別介紹。 Distance Metric和前面一樣先計算出pdist_matrix，和相應的adjacency mask跟adjacency_not mask： 1234pdist_matrix = _distance_metric(embedding, squared=True)adjacency = np.equal(labels, tf.transpose(labels)).astype(np.float32)adjacency_not = np.logical_not(adjacency).astype(np.float32) negatives_outside將pdist_matrix複製batch次，會得到pdist_matrix_tile，其shape為(batch*batch, batch)，這是為了之後要挑出Semi-Hard的triplet pair而計算： 1pdist_matrix_tile = tf.tile(pdist_matrix, [batch_size, 1]) 同樣將adjacency_not複製batch次，並且將pdist_matrix根據row展開成一列其shape為(batch*batch, 1)，讓pdist_matrix_tile中每一個element依序和展開的pdist_matrix相比，大於為Ture、反之False，最後再和batch倍的adjacency_not(為negative的所在)做and運算，例子如下： 12345678910111213141516171819202122232425262728293031323334353637'''np.reshape(np.transpose(pdist_matrix), [-1, 1])------------------------------------ex. pdist_matrix = [[ 0. 11. 11.] [11. 0. 24.] [11. 24. 0.]]轉換成(batch*batch,1):[[ 0.], [11.], [11.], [11.], [ 0.], [24.], [11.], [24.], [ 0.]]依序和展開的`pdist_matrix`相比np.greater(pdist_matrix_tile, np.reshape(np.transpose(pdist_matrix), [-1, 1]))------------------------------------[[False True True] [False False True] [False True False] [False False False] [ True False True] [False False False] [False False False] [False False False] [ True True False]] np.logical_and(a, b)------------------------------------[[False True False] [[False True True] [[False True False] [ True False True] [False False True] [False False True] [False True False] [False True False] [False True False] [False True False] [False False False] [False False False] [ True False True] and [ True False True] = [ True False True] [False True False] [False False False] [False False False] [False True False] [False False False] [False False False] [ True False True] [False False False] [False False False] [False True False]] [ True True False]] [False True False]] '''a = np.tile(adjacency_not, [batch_size, 1])b = np.greater(pdist_matrix_tile, np.reshape(np.transpose(pdist_matrix), [-1, 1]))mask = np.logical_and(a, b) 這邊將pdist_matrix中的batch*batch展開，將每一筆當作AP和對應的row去比較(第一筆為row 1對column 1的距離，讓他對第一個row比較，如下圖)，所以這邊評估在每個row中哪些比他本身更大，更大的作為True。 (1.1對1.all比較，1.2對2.all比較，… 2.1對1.all比較，2.2對2.all比較，… 3.1對1.all比較，3.2對2.all比較，…) 接下來透過tile過的adjacency_not，把屬於不同label並且距離大於AP(pdist_matrix中每個element)的都挑選出來了。 接合前面的np_masked_minimum function我們可以得到AN的Semi-Hard的候選清單，也就是AN&gt;AP的情況下最小的AN： 12345# negatives_outside: smallest D_an where D_an &gt; D_ap.negatives_outside = np.reshape(np_masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size])negatives_outside = np.transpose(negatives_outside) negatives_inside以上滿足了AP&lt;AN的狀況下找尋可計算pair，但有可能會存在AN&lt;AP的時候，這個時候要找最遠的AN，和AP比較，也就是easy negatives： 12# negatives_inside: largest D_an.negatives_inside = np.tile(np_masked_maximum(pdist_matrix, adjacency_not), [1, batch_size]) semi_hard_negatives將前面的mask，也就是AN&gt;AP的情況下是否擁有的AN，做reduce_sum。換句話說就是將AN&gt;AP的狀況下存在AN的element為True (也就是semi-hard的部分)，使用negatives_outside的距離，反之用negatives_inside： 1234567891011'''np.where(condition, x, y):if condition: return x else: return y'''mask_final = np.reshape(np.greater(np.sum(mask.astype(np.float32), 1, keepdims=True),0.0), [batch_size, batch_size])mask_final = np.transpose(mask_final)semi_hard_negatives = np.where(mask_final, negatives_outside, negatives_inside) 最後在滿足mask_final的情況下選擇negatives_outside和negatives_inside，作為AN來計算Triplet Loss，得到loss_mat。 Semi-Hard Triplet因為在對角線部分為anchor對anchor的距離，這邊需要將它過濾掉，因為不是這邊需要的，所以算出label相同的mask之後減掉對角線，就可以找到positive的位置，將前面的loss_mat乘上這邊的mask，算總和後除以positive數量，就可以得到最後的triplet loss： 12345678910111213loss_mat = np.add(margin, pdist_matrix - semi_hard_negatives)mask_positives = adjacency.astype(np.float32) - np.diag(np.ones([batch_size]))# Take all positive pairs except the diagonal.num_positives = tf.math.reduce_sum(mask_positives)triplet_loss = tf.math.truediv( tf.math.reduce_sum( tf.math.maximum(tf.math.multiply(loss_mat, mask_positives), 0.0) ), num_positives,) Code Link以上所有的code都是在Google Colab上面執行，版本為2.2.0。 Github：NeuralNetwork-01 Batch Hard and Semi-Hard Triplet Loss 參考資料Triplet-Loss原理及其实现","link":"/2020/02/04/NeuralNetwork-01/"},{"title":"hexo系列-00 hexo簡介＆環境安裝","text":"A fast, simple &amp; powerful blog framework 前言一直以來就有想要架設個人網站的想法，之前在學寫HTML的時候，有試過用github.io的功能，他可以直接把你寫的網頁直接呈現在外部ip。(在大學的時候有想過用這個功能把專題直接讓每個人玩，不過後來發現，他只能用靜態網頁所以後來就不了了之。) 身為一個懶惰又想要讓自己的網站很炫能看的資訊工程學生，在一看到hexo這個工具，就立刻架設了一個範本，也就是現在你所看到的這個網站，經過研究一段時間後發現，架設這個網站只需要簡單的幾個指令就可以完成，基本上不需要資訊工程或是有編程經驗的背景就可以使用了。 不過要注意的是hexo是一個基於Node.js的靜態blog工具，可以很方便的將生成的網頁直接放在Github上面，不過要注意的是他跟基於PHP的WordPress不一樣，如果你想搭建功能比較複雜的網頁或是WebAPP的話，還是採用動態網站比較好。 之後會慢慢的完善這個網頁，接下來就直接開始介紹怎麼使用hexo這個工具吧～ 環境安裝、配置NodeJS/NPMNodeJS是能夠在電腦運行JavaScript的開放原始碼，幾本上所有在寫前端的程序猿都會需要使用，安裝方法很簡單，去NodeJS官方網站下載一個LTS的版本就可以了，如果你電腦安裝過了就可以直接跳過。 有許多人在JavaScript上發佈、使用許多模塊，要調用也十分容易，其中NPM是最有名的社群，也是國際上最為流行的Node模塊管理工具，現在的NodeJS已經集成了NPM，所以不需要再去安裝。 Git/Github去Git官網下載和自己作業系統相對應的安裝包，另外如果沒有Github帳戶的人也需要去申請一個。 另外要記得設定全局變量還有ssh-key 123git config --global user.name &quot;Your Github username&quot;git config --global user.email &quot;Your Github mail address&quot;ssh-keygen -t rsa -C &quot;Your Github mail address&quot; 然後可以在家目錄~/裡面看到.ssh文件夾，在裡面會有id_rsa.pub這個檔案，可以使用pbcopy這個指令來複製key。 1pbcopy &lt; ~/.ssh/id_rsa.pub 然後到Github SSH and GPG keys新增你的key，標題隨意打一個就行，新增完後以後要發文就不需要再輸入Github的密碼了。 Hexohexo可以直接使用npm來進行安裝： 1npm install hexo-cli -g 到這邊基本的環境就算安裝完成。 進入你要創建hexo的目錄(建議創建的目錄為XXX.github.io)，接下來初始化hexo的環境： 1234hexo init XXX.github.iocd XXX.github.ionpm installhexo server 到這個步驟你就可以直接用瀏覽器打開localhost:4000(默認的port，也可以用hexo server -p XXXX來指定你的連接埠)，預設的主題是landscape。 到這裡你就可以開始使用你個人的blog了，下一篇會介紹如何更改主題、上傳到Github Page等等。 Hexo建置在使用的hexo之前，我想各位都已經找到自己感興趣的網站樣板了吧？！(至少我是XD) 如果還沒有開始找想要的樣板也沒關係，這裏列出了很多不同的樣板可以去參考看看。 主題安裝這裡我挑選的是Icarus作為我的主題，然後直接在~/XXX.github.io這個目錄下面輸入： 1git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus 這樣就可以直接把主題安裝到目錄中的themes資料夾了。 如果在這之前你是使用過hexo的人要轉換主題，你要先執行： 1hexo clean 清除之前主題渲染過內容的檔案，再重新渲染一次才不會有問題。 設置文件在執行完上面步驟之後，你會在資料夾發現兩個_config.yml，一個在XXX.github.io資料夾內，另一個在剛剛下載的主題內。 接下來將XXX.github.io內的_config.yml打開，將theme改寫成你主題的名字： 1theme: icarus 接著執行選染的指令： 12hexo generatehexo g #簡寫當然也是可以的 最後就可以在瀏覽器看結果囉～ 1hexo server 預設地址為：http://localhost:4000 新增貼文接下來是新增貼文，在目錄中使用下面這個指令就可以新增貼文了： 1hexo new post 'title' 然後在XXX.github.io/source/_posts/這資料夾內就會看到剛剛新增的title.md檔案，文章標題默認會和檔案名稱一樣，打開這個md檔長得像這樣： 12345---title: titledate: 2019-12-10 15:05:40tags:--- 這邊就是單純的Markdown語法，無須多說。不過在頂部的設定區有一些有趣的選項，譬如tag, categories, thumbnail, toc，其中thumbnail和toc分別代表的是縮圖跟目錄，可以用以下的方式設定： 12345678---title: titledate: 2019-12-10 15:05:40tags: [A,B]categories: Cthumbnail: /uploads/YourImage.JPGtoc: true--- 這邊要注意的是圖片的位置，這邊個人建議是在XXX.github.io/public/裡面新增一個資料夾叫做uploads，之後你文章中所使用的任何圖片都可以上傳到這裡在用/uploads/YourImage.JPG的方式指定到目標位置。 當然如果你要建立子資料夾來管理圖片也是可以的，之後文章會介紹post_asset_folder讓圖片可以放在_posts裡面，用文章的名稱來管理用到的圖片。 上傳到Github前面有申請過Github的帳戶，現在我們要將網站發佈在Github Page上面，首先要做的是打開XXX.github.io下的_config.yml檔案，找到Deployment將其改成像下面這段： 1234567# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: 'git' repo: https://github.com/YourAccount/XXX.github.io.git branch: master message: 變更成你的配置，不過不建議在message加上內容，我們可以在後面加上message的訊息，記得要先generate才可以上傳到你的Github帳戶： 12hexo generatehexo depoly -m &quot;github message&quot; 建議在這裡加上附註，因為可以使用一些git的技巧，直接在-m後面加上要傳上去的附註，當然也可以將上傳的時間點加在附註上面，像是這樣的形式： 1hexo d -m &quot;Site updated: `date +'%Y-%m-%d %H:%M:%S'`&quot; 結語以上就是關於hexo的基本操作方式，接下來會針對_config.yml檔案裡面的參數去做介紹。","link":"/2019/12/09/hexo-00/"},{"title":"hexo系列-01 hexo簡單配置","text":"theme下的_config.yml前面有介紹過hexo在生成主題之後會有兩個_config.yml，這邊著重介紹在theme中的設定(絕對不是hexo原生的_config.yml沒什麼好介紹的) favicon&amp;logo首先就是favorites icon和logo~ 你可以在_config.yml裡面找到： 1234567# Path or URL to the website's iconfavicon: /images/favicon.png# Path or URL to the website's logo to be shown on the left of the navigation bar or footerlogo: /images/logo.png 然後打開你的目錄XXX.github.io/public/images/裡面找到相對應的圖檔，間單的替換+更改檔名就可以放上你想要的圖片囉～ share分享的方式Icarus提供了許多方式，預設是： 12# Shareshare: default # options: jiathis, bdshare, addtoany, default 這邊我使用的是AddThis在連結中註冊帳戶，他可以透過google, Facebook或是Twitter註冊帳戶，這個網站不只有分享按鈕的JavaScript，詳細功能可以自行去探索，設定好後會得到像是這樣的code 1//s7.addthis.com/js/300/addthis_widget.js#pubid=xxxxxxxx 將share那段替換成： 1234# Shareshare: type: addthis install_url: //s7.addthis.com/js/300/addthis_widget.js#pubid=xxxxxxxx # (required) 如此就可以直接在你的post上面看到我頁面上的分享按鈕了～ Donate當你建置好你的網站後你可能會發現下面這樣的狀況： 這是因為你在Donate的選項中沒有設置完全，直接把它註解掉就可以解決這個問題了。 1234567891011121314151617181920212223# donate: # - # # Donation entry name # type: alipay # # Qrcode image URL # qrcode: '' # - # # Donation entry name # type: wechat # # Qrcode image URL # qrcode: '' # - # # Donation entry name # type: paypal # # Paypal business ID or email address # business: 'V6DFAWSEDJJHE' # # Currency code # currency_code: U # - # # Donation entry name # type: patreon # # URL to the Patreon page # url: '' 當然如果你要設置Donate的帳戶也完全沒問題😜 highlight接著是highlight選項，這個是程式碼區塊的顯示格式，可以透過這裡去預覽、這裡去下載。 簡單的將highlight名稱替換成你想要的樣板名稱就可以裡： 123456789# Code highlight settingshighlight: # Code highlight themes # https://github.com/highlightjs/highlight.js/tree/master/src/styles theme: zenburn # Show code copying button clipboard: true # Default folding status of the code blocks. Can be &quot;&quot;, &quot;folded&quot;, &quot;unfolded&quot; fold: unfolded 這裏我選擇的是zenburn，理由就是我覺得好看這個暗色主題黑的剛剛好，不會想其他主題一樣太黑，或者是不夠黑。 widgets這個選項就是調整你在頁面上所看到所有一塊塊區域的內容跟功能，第一個區塊就是網頁簡單名片： 在_config.yml的widgets第一個區塊就是相關的設定，包含像是位置、作者、還有圖片等等。在預設中沒有的是Envelope選項，也就是上面那張圖的右下角，可以通過更改social_links來將你的信箱新增上去： 12345678910social_links: Github: icon: fab fa-github url: 'https://github.com/AugustusHsu' Facebook: icon: fab fa-facebook url: 'https://www.facebook.com/HsuAugustus' Envelope: icon: fas fa-envelope url: mailto:jimhsu11@gmail.com 這樣設置後，只要點擊你的信箱那個圖示，電腦會自動跳到寫信的應用程式(不過這年代還有誰會用Email來寫信😆) 其他功能我都是使用預設選項，當然其中會有像是： 1position: left 這樣的選項，你可以自行調整要放在左右那一邊，當然你也可以直接註解掉整塊來取消這個功能。 Image管理在Hexo你的發文可以透過MarkDown語法來編寫，所以在引用圖片的時候是可以透過第三方的網站來上傳圖片，再利用： 1！[title](image link) 來展示你的圖片，那如果想要將圖片放在你的網頁資料夾中的話，要怎麼引用呢？ hexo-asset-image這邊可以直接安裝這個插件，在新增貼文的時候會同時產生一個同名的資料夾，把圖片丟進資料夾再飲用就可以了。 在XXX.github.io資料夾輸入以下命令： 1npm install hexo-asset-image --save 另外在XXX.github.io中的_config.yml： 1post_asset_folder: true 將它改成true，這樣在新增貼文的時候就會自動產生同名的資料夾了。 實際運用如果你的圖片放在同名資料夾的話，在文章中要引用圖片的話，要像下面這個例子一樣： 1！[title](image_name.jpg) 無需加上資料夾的名稱，直接打你的圖片檔名就可以引用了。 不過這邊要注意的是如果你這樣打，在MarkDown編輯器中，你圖片會看不到，還有如果你是一邊啟動hexo server在編輯的話，你在網頁上圖片也是會顯示不出來，要執行過一次： 1hexo g 才能正常的在localhost:4000中看到圖片。 留言設置文章當然免不了討論問題，那在文章底部新增一個互動機制也就是留言功能，就在所難免。 在這個留言設置中，我只舉出兩種我有實際操作過的方法，其他像是gitment在Icarus列出的方法就請有興趣的朋友自行研究了。 gitalkgitalk是使用github上面的issue功能實現的留言討論功能，所以要跟github做連結。 OAuth OAuth是一個開放標準，允許用戶讓第三方應用存取該用戶在某一網站上儲存的私密的資源，而無需將用戶名稱和密碼提供給第三方應用。 –Wiki 也就是要授權github來儲存對話紀錄，點擊這裡來申請一個OAuth 其中Homepage URL跟Authorization callback URL請填你github.io的網址，name就簡單填個就行。 申請完會得到Client ID跟Client Secret將這兩項填入： 1234567891011comment: type: gitalk owner: xxxxxxxx # (required) GitHub user name repo: xxxxxxxx # (required) GitHub repository name client_id: xxxxxxxx # (required) OAuth application client id client_secret: xxxxxxxx # (required) OAuth application client secret admin: xxxxxxxx # (required) GitHub repo owner and collaborators who can initialize github issues # Can either be a string or an array. # admin: # - xxxxxx1 # - xxxxxx2 owner跟admin就直接填你github帳戶名稱就行。 一開始你可能會遇到像是這樣： 這時候直接按下去就會要你去登入並授權這個應用功能： 結束後你就可以在文章下方看到跟我一樣的留言區塊了。 facebookfacebook的話比較簡單，不過我之前有遇到過他的寬度不太合的狀況，所以比較推薦使用gitalk的方式來增加留言功能。 facebook的方式一樣要先授權，所以點這裡將你github.io的網址填入，接著按下取得程式碼就可以了。 再來要在_config.yml裡面把comment的設定更改成facebook: 12comment: type: facebook 這樣就設定完成了。 補充你在首頁看到我的文章會看到Read More這個框框，這個是MarkDown的語法，直接在你想隱藏的段落前加上： 1&lt;!--more--&gt; 就可以摺疊你的貼文了。","link":"/2019/12/10/hexo-01/"},{"title":"hexo系列-03 讓google可以搜尋到你的網站","text":"前言原本以為要讓自己的網站在網路上可以被搜尋到，只要能用網址打開網站，之後Google搜尋引擎就可以搜尋到相對應的內容，沒有想到事情不是那麼簡單的我還是太年輕了。 要讓搜尋引擎能搜到自己的網站，首先要去Google網站管理員的Google Search Console提交網站的一些設定，詳細的會在下面一一列出。 安裝sitemap套件1npm install hexo-generator-sitemap --save 安裝這個套件會直接幫你生成需要的檔案，接著在theme/_config.yml加上下面這段： 123#Sitemapsitemap: path: sitemap.xml 接下來用： 1hexo g 生成sitemap.xml的檔案，位於XXX.github.io/public/中。 創建robots.txt在XXX.github.io/source中創建robots.txt文件： 12345678910111213# hexo robots.txtUser-agent: *Allow: /Allow: /archives/Allow: /categories/Allow: /tags/Allow: /about/ # Disallow: /js/# Disallow: /css/# Disallow: /fancybox/Sitemap: https://augustushsu.github.io/sitemap.xml robots.txt是用來告訴網路搜尋引擎的漫遊器(又稱網路蜘蛛)，此網站中的哪些內容是不應被搜尋引擎的漫遊器取得的，哪些是可以被漫遊器取得的。 其中Allow後面加的就是你的menu，也就是允許漫遊器搜尋的到網頁，而Disallow則相反。 你可以將在測試的網頁資料夾寫在Disallow上，這樣一些漫遊器就不會去搜到你不想公開的網頁囉，詳細的說明可以參考Googel文件，還有這篇文章。 Google Search Console前面有說要讓Google搜尋的到你需要在Google Search Console中填寫關於你訊息，登入Google帳戶後，你應該會看到這樣的畫面： 輸入你Github上的網址，之後會要你去驗證： 這邊選擇的是用HTML標記，將google提供的html程式碼複製到XXX.github.io/themes/icarus/layout/common/head.ejs，直接加在最上面就可以： 接著上傳到GitHub： 1hexo -g d 按下驗證，如果設置的正確，就會跳出以下畫面： 接下來要將剛剛建的sitemap.xml提交到Google Search Console： 驗證之後，Google會花一些時間將你的網站建檔，等過了一天你就可以用Google Search Console來分析自己的網頁囉～ robots.txt點選網址審查把你的網頁貼上，會顯示正在從 Google 索引擷取資料完成後，點選查看以檢索的網頁再點更多資訊就可以看到前面Disallow不想讓其他人看到的部分了： Google Analytics打開Google Analytics網站，註冊一個帳號，然後點選追蹤程式碼，複製你的追蹤ID，形式大概是UA-XXXXXXXX-X。 將上面的ID輸入到Icarus下_config.yml檔案中的： 123google-analytics: # Google Analytics tracking id tracking_id: UA-XXXXXXXX-X 最後再將你的成品上傳到Github就完成囉～ 1hexo -g d","link":"/2019/12/14/hexo-03/"},{"title":"hexo系列-02 hexo個人化設置","text":"前言在用主題模板的時候，總有些時候會覺得網頁版面怪怪的、不盡人意的地方，那要怎麼改呢？ 這邊列出了我對Icarus主題的改動地方，這篇的東西都是參考下列網址： https://www.alphalxy.com/2019/03/customize-icarus https://dp2px.com/2019/06/04/icarus-theme/ https://github.com/ppoffice/hexo-theme-icarus/issues/379 然後我這邊不是全部採用，而是選取部分內容時做到我的網站上，不過話說前頭，本人不是專業的前端工程師，所以大部分內容都只是參考一下就直接照抄，如果對本文內容不夠滿意的話，建議可以直接去看上面的網址內容。 佈局Icarus的主題默認上是三欄式網頁佈局，不過這個模式在瀏覽文章的時候總會覺得版面有些太滿，所以這邊我將閱讀文章的佈局改成兩欄式的佈局。 文章佈局-兩欄式佈局打開includes/helpers/layout.js找到下面紅字那行替換成綠字那行，記得不要複製到+號： 12345678910const widgets = hexo.extend.helper.get('get_config').bind(this)('widgets');- return widgets.filter(widget =&gt; widget.hasOwnProperty('position') &amp;&amp; widget.position === position);+ if (this.page.layout !== 'post') {+ return widgets.filter(widget =&gt; widget.hasOwnProperty('position') &amp;&amp; widget.position === position);+ }+ if (position === 'left') {+ return widgets.filter(widget =&gt; widget.hasOwnProperty('position') &amp;&amp; (widget.type === 'toc' || widget.type === 'profile'));+ } else {+ return []+ } 這邊可以注意到page.layout是頁面的類型，當他是'post'時代表當前是文章閱讀的模式，當然你也可以針對其他頁面去做調整，像是index代表首頁、tag代表標籤頁。 詳細的網頁類別可以點這裡查到。 if (position === 'left')這段代表的是小工具載入的位置，你也可以設定成'right'來讓你後續要載入的小工具展是在右邊。 後面的widget.type代表的是要列在上面指定位置的小工具，可以透過||來增加你想展示的小工具。 接下來因為兩籃式佈局跟三欄式佈局整體的寬度不一樣，所以要調整layout/common/widget.ejs這個檔案： 123456&lt;% function side_column_class() { switch (column_count()) { case 2:- return 'is-4-tablet is-4-desktop is-4-widescreen';+ return 'is-4-tablet is-4-desktop is-3-widescreen'; case 3: 還有這個檔案layout/layout.ejs： 12345678910-&lt;body class=&quot;is-&lt;%= column_count() %&gt;-column&quot;&gt;+&lt;body class=&quot;is-3-column&quot;&gt; &lt;%- partial('common/navbar', { page }) %&gt; &lt;% function main_column_class() { switch (column_count()) { case 1: return 'is-12'; case 2:- return 'is-8-tablet is-8-desktop is-8-widescreen';+ return 'is-8-tablet is-8-desktop is-9-widescreen'; 因為Icarus有針對響應式去做設計，所以要更改source/css/style.styl，針對不同螢幕寬度有相應的呈現： 12345678910111213 .is-2-column .container max-width: screen-desktop - 2 * gap width: screen-desktop - 2 * gap+ .is-3-column .container+ max-width: screen-widescreen - gap+ width: screen-widescreen - gap @media screen and (min-width: screen-fullhd)+ .is-3-column .container+ max-width: screen-fullhd - 2 * gap+ width: screen-fullhd - 2 * gap .is-2-column .container max-width: screen-widescreen - 2 * gap width: screen-widescreen - 2 * gap 標題佈局-更新時間和icon接下來新增文章標題的更新時間和標籤icon，更改layout/common/article.ejs： 123456789 &lt;% if (post.layout != 'page') { %&gt; &lt;div class=&quot;level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto&quot;&gt; &lt;div class=&quot;level-left&quot;&gt;- &lt;time class=&quot;level-item has-text-grey&quot; datetime=&quot;&lt;%= date_xml(post.date) %&gt;&quot;&gt;&lt;%= date(post.date) %&gt;&lt;/time&gt;+ &lt;time class=&quot;level-item has-text-grey&quot; datetime=&quot;&lt;%= date_xml(post.date) %&gt;&quot;&gt;&lt;i class=&quot;far fa-calendar-alt&quot;&gt;&amp;nbsp;&lt;/i&gt;&lt;%= date(post.date) %&gt;&lt;/time&gt;+ &lt;% if (post.updated &amp;&amp; post.updated &gt; post.date) { %&gt;+ &lt;time class=&quot;level-item has-text-grey is-hidden-mobile&quot; datetime=&quot;&lt;%= date_xml(post.updated) %&gt;&quot;&gt;&lt;i class=&quot;far fa-calendar-check&quot;&gt;&amp;nbsp;&lt;/i&gt;&lt;%= date(post.updated) %&gt;&lt;/time&gt;+ &lt;% } %&gt; &lt;% if (post.categories &amp;&amp; post.categories.length) { %&gt; 然後要刪除source/js/main.js中的部分程式碼： 12345- if (typeof(moment) === 'function') {- $('.article-meta time').each(function () {- $(this).text(moment($(this).attr('datetime')).fromNow());- });- } 我這邊遇到了一個問題：在source/js/main.js找不到上面那段刪除，這邊猜測是要執行hexo g之後才會產生上面那段程式碼，如果找不到要刪除的程式碼，記得要去generate一次你的網站。 完成的模樣會像是這樣的狀況： 文章結尾佈局-修改tag展示這邊在文章底部增加了一個hr，然後針對文章的預覽還有結尾加上了tag的icon，修改layout/common/article.ejs這個檔案： 123456789101112131415161718192021222324252627282930313233343536 &lt;% if (!index &amp;&amp; post.tags &amp;&amp; post.tags.length) { %&gt;+ &lt;hr style=&quot;height:1px;margin:1rem 0&quot;/&gt; &lt;div class=&quot;level is-size-7 is-uppercase&quot;&gt; &lt;div class=&quot;level-start&quot;&gt; &lt;div class=&quot;level-item&quot;&gt;- &lt;span class=&quot;is-size-6 has-text-grey has-mr-7&quot;&gt;#&lt;/span&gt;+ &lt;i class=&quot;fas fa-tags has-text-grey&quot;&gt;&lt;/i&gt;&amp;nbsp; &lt;%- list_tags(post.tags, { class: 'has-link-grey ', show_count: false,- style: 'link'+ style: 'link',+ separator: ',&amp;nbsp;' }) %&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;% } %&gt; &lt;% if (index &amp;&amp; post.excerpt) { %&gt;- &lt;div class=&quot;level is-mobile&quot;&gt;+ &lt;hr style=&quot;height:1px;margin:1rem 0&quot;/&gt;+ &lt;div class=&quot;level is-mobile is-flex&quot;&gt;+ &lt;div class=&quot;level-start&quot;&gt;+ &lt;% if (post.tags &amp;&amp; post.tags.length) { %&gt;+ &lt;div class=&quot;level-item is-size-7 is-uppercase&quot;&gt;+ &lt;i class=&quot;fas fa-tags has-text-grey&quot;&gt;&lt;/i&gt;&amp;nbsp;+ &lt;%- list_tags(post.tags, {+ class: 'has-link-grey ',+ show_count: false,+ style: 'link',+ separator: ',&amp;nbsp;'+ }) %&gt;+ &lt;/div&gt;+ &lt;% } %&gt;+ &lt;/div&gt; &lt;div class=&quot;level-start&quot;&gt; 手機顯示優化在使用手機瀏覽網站的時候，隱藏archive和tagcloud小工具，修改layout/widget/archive.ejs： 12-&lt;div class=&quot;card widget&quot;&gt;+&lt;div class=&quot;card widget is-hidden-mobile&quot;&gt; layout/widget/tagcloud.ejs： 12-&lt;div class=&quot;card widget&quot;&gt;+&lt;div class=&quot;card widget is-hidden-mobile&quot;&gt; 當然，你可以在layout/widget/裡面找你想要隱藏的小工具，一樣套用上面的方式。 固定目錄將文章的目錄固定在一個位置，不會隨著網頁的滾動而看不到目錄，這邊只需簡單的修改layout/widget/toc.ejs就可以了： 12-&lt;div class=&quot;card widget&quot; id=&quot;toc&quot;&gt;+&lt;div class=&quot;card widget column-left is-sticky&quot; id=&quot;toc&quot;&gt; 功能接下來針對網頁的功能去做新增跟修正。 版權宣告在layout/common/article.ejs新增： 1234567891011121314 &lt;div class=&quot;content&quot;&gt; &lt;%- index &amp;&amp; post.excerpt ? post.excerpt : post.content %&gt; &lt;/div&gt;+ &lt;% if (!index &amp;&amp; post.layout === 'post' &amp;&amp; post.copyright !== false) { %&gt;+ &lt;ul class=&quot;post-copyright&quot;&gt;+ &lt;li&gt;&lt;strong&gt;文章標題：&lt;/strong&gt;&lt;a href=&quot;&lt;%= post.permalink %&gt;&quot;&gt;&lt;%= page.title %&gt;&lt;/a&gt;&lt;/li&gt;+ &lt;li&gt;&lt;strong&gt;文章作者：&lt;/strong&gt;&lt;a href=&quot;&lt;%= theme.url %&gt;&quot;&gt;&lt;%= theme.author %&gt;&lt;/a&gt;&lt;/li&gt;+ &lt;li&gt;&lt;strong&gt;文章連結：&lt;/strong&gt;&lt;a href=&quot;&lt;%= post.permalink %&gt;&quot;&gt;&lt;%= post.permalink %&gt;&lt;/a&gt;&lt;/li&gt;+ &lt;li&gt;&lt;strong&gt;發佈時間：&lt;/strong&gt;&lt;%= post.date.format(&quot;YYYY-MM-DD&quot;) %&gt;&lt;/li&gt;+ &lt;li&gt;&lt;strong&gt;版權聲明：&lt;/strong&gt;本博客所有文章除特別聲明外，均採用 &lt;a href=&quot;https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh&quot; rel=&quot;external nofollow&quot; target=&quot;_blank&quot;&gt;CC BY-NC-SA 4.0&lt;/a&gt; 許可協議。引用請註明出處！+ &lt;/li&gt;+ &lt;/ul&gt;+ &lt;% } %&gt; &lt;% if (!index &amp;&amp; post.tags &amp;&amp; post.tags.length) { %&gt; 然後增加css樣式，在source/css/style.styl新增： 1234567891011/* --------------------------------- * Copyright * --------------------------------- */+.post-copyright+ font-size: 1rem+ letter-spacing: 0.02rem+ word-break: break-all+ margin: 2.5rem 0 0+ padding: 1rem 1rem+ border-left: 3px solid #FF1700+ background-color: #F9F9F9 默認使用目錄小工具正常在寫文章的時候，要啟用目錄的功能時，需要在meta資料中加入toc: true來開啟目錄小工具，不過大多數時候都會在文章中使用目錄，所以這邊讓他在默認的時候加入toc: true，修改includes/helpers/config.js： 1234567 return defaultValue; } else { const property = readProperty(specs, configName);- return property === null ? null : property[descriptors.defaultValue];+ const result = property === null ? null : property[descriptors.defaultValue];+ return (configName === 'toc' &amp;&amp; this.page.layout === 'post' &amp;&amp; result === null) ? true : result; } footer顯示一組icon在版權的地方有寫到採用CC BY-NC-SA 4.0，而CC BY-NC-SA 4.0的icon是四個一組，所以要讓在配置link.icon可以是一個數組的方式呈現。 修改layout/common/footer.ejs： 1234 &lt;% } else { %&gt;- &lt;i class=&quot;&lt;%= link.icon %&gt;&quot;&gt;&lt;/i&gt;+ &lt;% for (let icon of (Array.isArray(link.icon) ? link.icon : [link.icon])) { %&gt;&lt;i class=&quot;&lt;%= icon %&gt;&quot;&gt;&lt;/i&gt;&amp;nbsp;&lt;% } %&gt; &lt;% } %&gt; 和includes/specs/icon_link.spec.js： 12345 icon: { [required]: true,- [type]: 'string',+ [type]: ['string', 'array'], [doc]: 'Link icon class names' 另外在_config.yml中修改成這樣： 123456789footer: links: CC BY-NC-SA 4.0: icon: - fab fa-creative-commons - fab fa-creative-commons-by - fab fa-creative-commons-nc - fab fa-creative-commons-sa url: 'https://creativecommons.org/licenses/by-nc-sa/4.0/' 樣式按鈕、背景顏色增加漸變讓一些按鈕(例如profile中的文章、分類等)有陰影、漸變的效果，修改source/css/style.styl： 123456 .menu-list li ul margin-right: 0+ .menu-list a+ transition: background-color 0.3s ease-in-out .menu-list a.level display: flex 區塊增加浮動效果:hover時曾大陰影面積，增加動畫屬性ease-in-out，修改source/css/style.styl： 12345 .card border-radius: 4px box-shadow: 0 4px 10px rgba(0,0,0,0.05), 0 0 1px rgba(0,0,0,0.1)+ &amp;:hover+ box-shadow: 0 6px 15px rgba(0,0,0,0.15), 0 0 1px rgba(0,0,0,0.1) 還有source/js/animation.js： 123 element.style.transform = '';- element.style.transition = 'opacity 0.3s ease-out, transform 0.3s ease-out';+ element.style.transition = 'opacity 0.3s ease-out, transform 0.3s ease-out, box-shadow 0.3s ease-in-out'; 這樣修改能看到在滑鼠移到各個區塊的時候會有淡淡的陰影，可以更改上面數值讓他變得明顯或是淡化它。 結語這篇是參考alphalxy這個網站上面的設置(並不是全都採用)，我在最上面也有留這個網站的連結，實作完之後版面的規劃跟細節，讓觀看的舒適度大大的增加也讓我比較順眼了。 如果你有找到更好的設置，歡迎留言給我，之後如果有其他有趣的功能會在實作後分享上來～","link":"/2019/12/11/hexo-02/"},{"title":"hexo系列-04 目前為止遇到的問題","text":"這邊羅列一些在使用Hexo建構自己的Blogger時遇到的一些問題。 Categories跟Sub-Categories第一個先記錄一個比較智障的問題：一直以來在其他hexo使用者的網頁中，他們的分類中下方有一個較小的分類，就是在網站中的categories下能有像是樹狀圖的層層結構，我一直以為那是需要額外安裝的，加上我文章量本來就比較少，所以我一直不以為意XD，就像下面那樣： 經過一番搜尋發現只需要在.md上面的categories改成： 1categories: [母類別, 子類別] 就可以產生如下的成果： 調整圖片的長寬這個問題跟上面的問題差不多，算是一個使用hexo的小技巧，基本上就是直接html的語法來調整長跟寬： 1&lt;img src=&quot;/image/test.jpg&quot; width=&quot;50%&quot; height=&quot;50%&quot;&gt; Highlight中的Clipboard和複製到行號如題所述，這也是困擾了我一陣子的問題，每次在寫Blogger，複製程式碼的時候都會一起複製到行號，另外點選右上角clipboard只會複製到第一行的內容： 經過搜尋發現是hexo-util這個套件的問題，在某一次更新後highlight的渲染出了問題，我透過更新npm還有hexo來解決： 12345npm updatenpm install hexocd /your/hexo/folder# 更新完後需要在渲染一次你的頁面hexo g 理論上這樣操作就可以解決這個問題了，不過我經過重開機後才解決這個問題，猜測也許是npm的一些設定在安裝好新版本的hexo後沒有更新，如果更新完後發現沒有效果，可以先試試看重新開機。 Google Drive圖片圖片在Github上使用，個人覺得當圖片檔案太大的時候，loading的時間會認人感覺有點久，有時候還會卡卡的，所以我找到將圖片放在Google Drive可以直接使用圖片的方法。 原本將圖片放在Google Drive上面，分享出來後會看到下面這個網址： 1https://drive.google.com/file/d/****************************/view?usp=sharing https://drive.google.com/file/d//view?usp=sharing 將星號的部分套用在下面的地方就可以直接使用了： 1https://drive.google.com/uc?export=view&amp;id=****************************","link":"/2020/06/03/hexo-04/"}],"tags":[{"name":"docker-19.03","slug":"docker-19-03","link":"/tags/docker-19-03/"},{"name":"nvidia-docker","slug":"nvidia-docker","link":"/tags/nvidia-docker/"},{"name":"native gpu","slug":"native-gpu","link":"/tags/native-gpu/"},{"name":"nvidia-container-toolkit","slug":"nvidia-container-toolkit","link":"/tags/nvidia-container-toolkit/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"ubuntu-18.04","slug":"ubuntu-18-04","link":"/tags/ubuntu-18-04/"},{"name":"xrdp","slug":"xrdp","link":"/tags/xrdp/"},{"name":"static ip","slug":"static-ip","link":"/tags/static-ip/"},{"name":"nvidia-gpu","slug":"nvidia-gpu","link":"/tags/nvidia-gpu/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"lvm","slug":"lvm","link":"/tags/lvm/"},{"name":"pv","slug":"pv","link":"/tags/pv/"},{"name":"vg","slug":"vg","link":"/tags/vg/"},{"name":"lv","slug":"lv","link":"/tags/lv/"},{"name":"Dockerfile","slug":"Dockerfile","link":"/tags/Dockerfile/"},{"name":"portainer","slug":"portainer","link":"/tags/portainer/"},{"name":"anaconda","slug":"anaconda","link":"/tags/anaconda/"},{"name":"cuda","slug":"cuda","link":"/tags/cuda/"},{"name":"cudnn","slug":"cudnn","link":"/tags/cudnn/"},{"name":"GAN","slug":"GAN","link":"/tags/GAN/"},{"name":"Generative Adversarial Network","slug":"Generative-Adversarial-Network","link":"/tags/Generative-Adversarial-Network/"},{"name":"Docker Hub","slug":"Docker-Hub","link":"/tags/Docker-Hub/"},{"name":"non-zero code 2","slug":"non-zero-code-2","link":"/tags/non-zero-code-2/"},{"name":"triplet loss","slug":"triplet-loss","link":"/tags/triplet-loss/"},{"name":"tensorflow","slug":"tensorflow","link":"/tags/tensorflow/"},{"name":"MNIST","slug":"MNIST","link":"/tags/MNIST/"},{"name":"batch hard","slug":"batch-hard","link":"/tags/batch-hard/"},{"name":"semi-hard","slug":"semi-hard","link":"/tags/semi-hard/"},{"name":"numpy","slug":"numpy","link":"/tags/numpy/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"Google Search Console","slug":"Google-Search-Console","link":"/tags/Google-Search-Console/"},{"name":"Google Analytics","slug":"Google-Analytics","link":"/tags/Google-Analytics/"},{"name":"sitemap","slug":"sitemap","link":"/tags/sitemap/"},{"name":"bug","slug":"bug","link":"/tags/bug/"},{"name":"categories","slug":"categories","link":"/tags/categories/"},{"name":"highlight","slug":"highlight","link":"/tags/highlight/"}],"categories":[{"name":"DL Machine","slug":"DL-Machine","link":"/categories/DL-Machine/"},{"name":"實作","slug":"實作","link":"/categories/%E5%AF%A6%E4%BD%9C/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"GAN","slug":"實作/GAN","link":"/categories/%E5%AF%A6%E4%BD%9C/GAN/"},{"name":"Neural Network","slug":"實作/Neural-Network","link":"/categories/%E5%AF%A6%E4%BD%9C/Neural-Network/"}]}